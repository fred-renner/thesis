\chapter{Discussion and Outlook}

The analysis conducted in this thesis demonstrates for the first time the potential and advantages of the \ac{neos} approach over traditional methods in a realistic particle physics search for Higgs boson pairs in a boosted topology. The results highlight the significant role of uncertainties when optimizing neural networks whose outputs are used for evaluating statistical tests in particle physics experiments. It has been shown that \ac{neos} provides a robust framework for systematic-aware neural network training and optimization. Although this analysis refrains from unblinding as, at the time of writing, not all uncertainties were calibrated, the result is without loss of generality and also not based solely on simulation, as collision data were used in the background estimate.


\section{Discussion}

\subsection{Improvement in Expected Cross-Section Limits}

The analysis shows a considerable improvement in expected cross-section limits for the \textsc{neos} approach compared to traditional methods. Specifically, for the $\kappa_{2V} = 0$ signal hypothesis, the \textsc{neos} approach demonstrates approximately a two-fold improvement in reducing the limits compared to both a maximum likelihood fit to the invariant mass of the Higgs pair system \mhh and a \ac{bce}-trained neural network. A similar enhancement is observed for the \textsc{neos} method when evaluated on the \ac{sm} signal. This significant improvement underscores \textsc{neos}' ability to optimize analysis performance when accounting for systematic uncertainties, solely due to the exploitation of the properties of the maximum likelihood fit.

The current best observed (expected) constraints at a 95\% confidence level on the \ktwov coupling, determined by the \ac{cms} collaboration, are $0.62 < \kappa_{2V} < 1.41 (0.66 < \kappa_{2V}< 1.37)$ for the same Higgs pair decay topology used in this analysis \citep{PhysRevLett.131.041803}. The latest results using the \ac{atlas} detector with the same topology are $0.52 < \kappa_{2v}< 1.52 (0.32 < \kappa_{2v}< 1.71)$ at the 95\% confidence level \citep{atlascollaboration2024searchpairproductionboosted}. This thesis improves the expected constraints using the latest advancements in object reconstruction, namely \ac{ufo} jets and the GN2X tagger $b$-tagging algorithm, and using \ac{neos} to $(0.55 < \kappa_{2v}< 1.48)$ at the 95\% confidence level. Although \ac{neos} represents an approximation, it outperforms classical methods without any caveats on the final results since cross-sectional limits are determined by using the \ac{neos} \ac{nn} without any \ac{neos} methods in the traditional analysis chain.


\subsection{Background Estimate and Uncertainty Reduction}
Searches involving hadronic final states depend crucially on a background estimate for the numerous potentially accompanying \ac{qcd} processes in the selection. It has been shown that if a strategy for a data-driven background estimate and a method estimating the uncertainty on this background estimate is given, \ac{neos} can effectively reduce this uncertainty, simplifying the analysis effort. For example, significant effort went into the background estimation of the resolved version of the $HH\rightarrow 4b$ analysis. Notably, this uncertainty is overestimated with the same extraction methods for the \mhh and \ac{bce}-trained model, whereas \ac{neos} optimizes this uncertainty to the maximum, as the pull shows almost perfect expected uncertainty behavior.

\subsection{Autoanalysis}
A key feature of \ac{neos} exploited in this work is its ability to draw conclusions on the existence of a physical process by using only the basic reconstructed objects and variables that encapsulate the process of interest. By setting up optimization parameters, which \ac{neos} then optimizes, the method reduces the need for successive manual optimizations. In this analysis, these parameters include cuts and methods for estimating the background.

The autoanalysis approach minimizes unwanted researcher bias that can be introduced through manual optimization, which may not lead to a global optimum and might unintentionally optimize on potential artifacts. By considering all parameters and their non-trivial correlations simultaneously, \ac{neos} ensures a more robust and unbiased optimization process. Additionally, autoanalysis opens the opportunity for a quick estimate of the sensitivity for any particle physics analysis.

\subsection{Optimization Capabilities}
A significant feature of \ac{neos} is its ability to include any parameterizable aspect in the optimization process, as long as these parameters are differentiable. This means that any parameter or even multiple neural networks dedicated to specific tasks within the analysis chain can be optimized simultaneously. However, there is a natural limit to this capability: an overly complex function can make gradient descent challenging. For instance, in cut optimization, each uncertainty and cut introduces a sigmoid differentiation, which can complicate the loss function's landscape.

\subsection{Asimov Significance}
When observing the evolution of the Asimov significance during the training of the \acp{nn} the correlation shows that it is a reasonable proxy for optimization. However the Asimov significance of \ac{neos} is 30\% larger than for the \ac{bce}-traing \ac{nn} being another prove for \ac{neos} increased performance even without the consideration of uncertainties. If \ac{neos} is not applicable it can be advisable when searching for a new process to implement a loss function that optimizes the Asimov significance which does not require any \ac{neos} methods. \citet{elwood2018direct} studied that such an approach can give improved results for analyses dominated by systematic uncertainties.


\section{Outlook}
Given the promising results obtained with \textsc{neos}, several avenues for future research and development are proposed. The following outlines potential areas for further investigation and refinement of the \textsc{neos} approach.

\subsection{Analysis Strategy}
As this is a reiteration of the same analysis with the latest reconstruction methods and analysis objects there is an opportunity for improvement when setting up the analysis strategy. This becomes evident when observing the $m_\text{H1}-m_\text{H2}$ massplane  in the \ac{sr} and also the definitions of the \ac{vr} and \ac{cr} which could ideally follow a concentrically increased \ac{sr} shape. The size of these regions could be additional parameters optimized by \ac{neos}.

\subsection{Refining Uncertainty Estimates}
The uncertainty estimate on the background in this work is, as studies have shown, one of the most important ones with the largest influence on the extracted limits, controlled by the strategy choice of the analyzer. It is executed most conservatively and could benefit from a definition with improved statistics, as the uncertainty estimate relies on very little statistics on the double Higgs tagged \ac{vr}. Furthermore, a true validation of the uncertainty estimate would require letting \ac{neos} optimize in an additional orthogonal region to the \ac{vr} and then estimate the uncertainty from the actual \ac{vr}. An idea here would be to split the \ac{vr} into four quadrants to avoid potential overfitting of the background uncertainty to the \ac{vr} used for both optimization and estimation.


\subsection{\ac{neos} Optimization}
Early studies attempted to optimize bin edges and tested different numbers of bins, but these efforts showed minimal differences in the limits. For \ac{neos}, this optimization seems redundant due to its ability to effectively place events into desired bins, eliminating the need to fine-tune bin edges.

There is potentially potential to optimize the training process of \ac{neos} further. Experimentation with different optimizers or architectures, such as transformers, could yield improvements. Additionally, tuning hyperparameters like the learning rate or the slopes of the sigmoid functions used in estimating cuts, as well as the bandwidth controlling the histogram shape from kernel density estimates, which by large controls the approximation inherent to \ac{neos}, could enhance performance.

Moreover, regularization techniques such as dropout, weight decay, or batch normalization, which help in finding lower minima, could be explored. Implementing second-order derivative methods like Newton's method or L-BFGS could also contribute to discovering lower minima.


\red{any nn benefits from more data. would be nice to see neos with more data could use run 3 bkg estimate or dijet mc
use all signal samples and input signal strength
}
\red{k-fold training! / cross validation}


\subsection{MC simulations for \ktwov Couplings}
While the impact on the determined cross-section limits when using a \ac{mc} generated $\kappa_{2V} = 0$ and a reweighted signal simulation is comparably small ($\sim$3\%), the accuracy of reweighting models for different \ktwov couplings remains uncertain. This uncertainty is particularly significant for \ktwov couplings, as only two of the six simulated samples explore a different \ktwov value. Future analyses could benefit from simulating several nominal signal samples that alter only the \ktwov coupling while maintaining $\kappa_\lambda$ and $\kappa_V$ at their \ac{sm} values. This approach would allow for more accurate modeling and provide opportunities for reoptimization for several \ktwov hypotheses.


\subsection{Associativity in Input and Model Data}
Another interesting path for research would be to study the relationships within the input data and those found by the \textsc{neos} model. Analyzers might gain insights into which event properties are crucial for the analysis and how they are associated when for instance studying what types of events are placed into which bins. Techniques such as Shapley values, as applied in the $b$-tagging study of muons in this thesis, could be useful in this context. Additionally, dimensional reduction methods like t-distributed stochastic neighbor embedding (t-SNE) can be used to study and visualize associations in the input data, uncovering underlying patterns and structures that inform the \textsc{neos} model's decision-making process.

\subsection{Future Approaches}

A follow-up approach proposed by the same developers as \textsc{neos} could be \textit{Learning Optimal Test Statistics in the Presence of Nuisance Parameters} by \citet{heinrich2022learningoptimalteststatistics}. This technique bypasses the profile likelihood building and develops test statistics shown to be equivalent to those obtained from profile likelihood ratios, which are traditionally used but computationally expensive. This approach could further simplify and accelerate the optimization procedure.

\red{
    binned transfer factor might be worth exploring --> is running.
}



\section{Conclusion}
In the context of $b$-tagging small-$R$ jets the potential offered by muons with a quality criterion from semileptonic decays was explored, resulting in up to a 40\% improved background rejection. The \ac{neos} approach represents a significant advancement in the optimization of neural networks for particle physics experiments, particularly in the presence of complex systematic uncertainties. `Autoanalysis' makes manual optimization efforts obsolete, allowing researchers to focus on the analysis strategy. The results obtained in this thesis highlight its potential to enhance the sensitivity and precision of analyses, opening new avenues for future research and discovery in particle physics.



% Prospects of non-resonant Higgs pair production
% at the HL-LHC and HE-LHC
% https://iopscience.iop.org/article/10.1088/1742-6596/1690/1/012149/pdf


% https://indico.cern.ch/event/1359386/contributions/5723345/attachments/2786832/4859053/ATLASdihiggs2024jan.pdf 

