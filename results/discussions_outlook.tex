
pick up on smt somewhere


neos
for outloook!
Learning Optimal Test Statistics in the Presence of
Nuisance Parameters
Lukas Heinrich
https://arxiv.org/pdf/2203.13079.pdf 
could potentially improve more for final state with more intricate information

NEOS
what actually happens if we are not applying vbf cuts? just optimized on significance.
revisit region definition with neos, chosen by intuition 
you can optimize anything 

wo einbauen? oder an welcher stelle ansetzen
einer der Vorteile von neos, weniger prone fÃ¼r human bias e.g. unblinding

automatically taken care of: systs don't blow up

you can optimize anything
add or remove arbitrary amount of blocks in the chain of figure 
train nn with neos and always can always go back

propose go back and make sure mc is correct

phi can also be bins and cuts

this analysis driven by stats

let neos choose cuts,
m_vbf, deta_vbf


stack several neural networks together!!! end to end training 
one for pairing, event selection 
stack arbitrarily 

does neos actually find the global minimum, how could one study it?


mention rel 21, but argue that comparison quite unfair, sell that this is great


neos
binning optimization tried, but actually fights against nn optimization


vbf cut

korrelationen kan man entagnlen
koreelation / anti korrelation zu background schweierig mit nur physik zu argumentieren 
so dass background estimate nicht schlecht wird.

truth studies would need to be done for signal/bkg estimate ? 

a future analysis could include ttbar subtraction
ttbar int note argument...


also the question is which things would be useful to do 


vbf cut prove of dont blindly follow s/b

could benefit from reopimization at different k2v

let neos do the cuts 

more accurate scan modeling with mc k2v modifications 

with new selection maybe a binned transfer factor might be worth exploring.

new selection can benefit from a signal region reopimitzimatzion --> massplane