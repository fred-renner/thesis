
pick up on smt somewhere


neos
for outloook!
Learning Optimal Test Statistics in the Presence of
Nuisance Parameters
Lukas Heinrich
https://arxiv.org/pdf/2203.13079.pdf 
could potentially improve more for final state with more intricate information

NEOS
what actually happens if we are not applying vbf cuts? just optimized on significance.
revisit region definition with neos, chosen by intuition 
you can optimize anything 
selling point ist binning ist optimiert, auch mit fixen bins
_m_jj_eta_jj does not help during training, maybe only if cuts are off?


wo einbauen? oder an welcher stelle ansetzen
einer der Vorteile von neos, weniger prone für human bias e.g. unblinding

automatically taken care of: systs don't blow up

you can optimize anything
add or remove arbitrary amount of blocks in the chain of figure 
train nn with neos and always can always go back

propose go back and make sure mc is correct

phi can also be bins and cuts

this analysis driven by stats

let neos choose cuts,
m_vbf, deta_vbf


stack several neural networks together!!! end to end training 
one for pairing, event selection 
stack arbitrarily 

does neos actually find the global minimum, how could one study it?


mention rel 21, but argue that comparison quite unfair, sell that this is great


neos
binning optimization tried, but actually fights against nn optimization


vbf cut

korrelationen kan man entagnlen
koreelation / anti korrelation zu background schweierig mit nur physik zu argumentieren 
so dass background estimate nicht schlecht wird.

truth studies would need to be done for signal/bkg estimate ? 

a future analysis could include ttbar subtraction
ttbar int note argument...


also the question is which things would be useful to do 


vbf cut prove of dont blindly follow s/b

could benefit from reopimization at different k2v

let neos do the cuts 

more accurate scan modeling with mc k2v modifications 

with new selection maybe a binned transfer factor might be worth exploring.
neos could actually try it

new selection can benefit from a signal region reopimitzimatzion --> massplane


no unblinding because sf
1.0 sf gn2x influence a lot the result! factor 1.4 


auch nochmal smt aufgreifen hier?


with neos forget about weird reweighting techniques and error estimation in resovled hh4b


------neos-------
gradient improve neos
inrcease gradient by worsening bkg shapesys with factor
cut slopes
bandwidth 
lr / optimizer
run cut optimization alone wihtout nn improvement
binning hat nichts gebracht

use w vector in training, didnt work…

this does not work:
xbb score entfernern
bandwidth also kind of optimized
more complicated arch not useufl
cuts at 0 also weird 
different bin nr not so important

cut optimierung verbessern mit slopes… 
auch müsste man herausfinden 
irgendwie gradieten verbessern auch zwischenhistogramme...

could retrain on sm, but stat error?

lukas neue idee erwähnen



antwrot auf frage wie kann binning übernehmen 
in theory could turn on binning, by figuring how to disable binning parameters so the opimization cant find gradients anymore 
degeneracy argument… hat nichts gebracht etc. nn should learn which bin


different arch didnt gain improvement


can see crux of situation, blindly going for Asimov significance, can not account for uncertainties
warum nicht auf s/b optimieren, kennt zwar keine unsicherheiten
gradient verstärken für bkg estiamte oder so


improve Training
dropout layers, different arch, 


pt_h2 lösen? …nein —> könnte man auch bei best fit versuchen
lets argue, were not available

eig noch eine VR
stats reichen nicht 
cut in half, use one for extraction, another one for actual validation dann in eig fit?

